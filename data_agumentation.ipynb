{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 224, 224, 3)\n",
      "(2000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_image(img_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, target_size)  # Resize the image\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "train_df = pd.read_csv(\"COMP90086_2023_TLLdataset/train.csv\")\n",
    "test_df = pd.read_csv('COMP90086_2023_TLLdataset/test_candidates.csv')\n",
    "train_left_images = np.array([load_image(f\"COMP90086_2023_TLLdataset/train/left/{img_name}.jpg\") for img_name in train_df['left']])\n",
    "train_right_images = np.array([load_image(f\"COMP90086_2023_TLLdataset/train/right/{img_name}.jpg\") for img_name in train_df['right']])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,         \n",
    "    width_shift_range=0.2,    \n",
    "    height_shift_range=0.2,   \n",
    "    shear_range=0.2,          \n",
    "    zoom_range=0.2,           \n",
    "    horizontal_flip=True,     \n",
    "    fill_mode='nearest'       \n",
    ")\n",
    "# Assuming train_left_images and train_right_images are your datasets\n",
    "\n",
    "def create_pairs(left_images, right_images):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(left_images)):\n",
    "        # Positive pairing\n",
    "        pairs.append([left_images[i], right_images[i]])\n",
    "        labels.append(1)\n",
    "\n",
    "        # Negative pairing\n",
    "        random_idx = np.random.randint(0, len(left_images))\n",
    "        while random_idx == i:  # Ensure it's not the same image\n",
    "            random_idx = np.random.randint(0, len(left_images))\n",
    "            \n",
    "        pairs.append([left_images[i], right_images[random_idx]])\n",
    "        labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "pairs, labels = create_pairs(train_left_images, train_right_images)\n",
    "\n",
    "# Splitting pairs for training\n",
    "train_pairs = [pairs[:, 0], pairs[:, 1]]\n",
    "\n",
    "print(train_left_images.shape)\n",
    "print(train_right_images.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangyusong/Desktop/CV final project/data_agumentation.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyusong/Desktop/CV%20final%20project/data_agumentation.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyusong/Desktop/CV%20final%20project/data_agumentation.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(left_iterator)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangyusong/Desktop/CV%20final%20project/data_agumentation.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         left_batch, left_labels \u001b[39m=\u001b[39m left_iterator\u001b[39m.\u001b[39mnext()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyusong/Desktop/CV%20final%20project/data_agumentation.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         right_batch, right_labels \u001b[39m=\u001b[39m right_iterator\u001b[39m.\u001b[39mnext()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyusong/Desktop/CV%20final%20project/data_agumentation.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39m# Make sure that your labels are in the correct shape for the batch size\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def cosine_similarity_tensors(vectors):\n",
    "    x, y = vectors\n",
    "    x = tf.keras.backend.l2_normalize(x, axis=-1)\n",
    "    y = tf.keras.backend.l2_normalize(y, axis=-1)\n",
    "    return tf.keras.backend.sum(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def siamese_with_dense121_and_cosine_similarity(input_shape):\n",
    "    left_input = layers.Input(input_shape)\n",
    "    right_input = layers.Input(input_shape)\n",
    "\n",
    "    # Use DenseNet121 as the base model\n",
    "    base_model = tf.keras.applications.DenseNet121(weights=None, include_top=False, input_shape=input_shape)\n",
    "    base_model.load_weights('/Users/yangyusong/Desktop/CV final project/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    encoded_left = base_model(left_input)\n",
    "    encoded_right = base_model(right_input)\n",
    "\n",
    "    # Flatten the encoded outputs (or you can add more layers if needed)\n",
    "    encoded_left = layers.Flatten()(encoded_left)\n",
    "    encoded_right = layers.Flatten()(encoded_right)\n",
    "\n",
    "    # Use cosine similarity to compute the similarity score\n",
    "    similarity_score = layers.Lambda(cosine_similarity_tensors)([encoded_left, encoded_right])\n",
    "\n",
    "    siamese_net = Model(inputs=[left_input, right_input], outputs=similarity_score)\n",
    "    return siamese_net\n",
    "\n",
    "input_shape = (224, 224, 3)  # Default input shape for DenseNet121\n",
    "model_dense121 = siamese_with_dense121_and_cosine_similarity(input_shape)\n",
    "model_dense121.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Assuming train_left_images and train_right_images are your datasets\n",
    "left_iterator = datagen.flow(train_left_images, batch_size=32, shuffle=False)\n",
    "right_iterator = datagen.flow(train_right_images, batch_size=32, shuffle=False)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(len(left_iterator)):\n",
    "        left_batch, left_labels = left_iterator.next()\n",
    "        right_batch, right_labels = right_iterator.next()        \n",
    "        # Make sure that your labels are in the correct shape for the batch size\n",
    "        batch_labels = labels[batch*32 : (batch+1)*32]\n",
    "        loss = model_dense121.train_on_batch([left_batch, right_batch], batch_labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
